{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 가져오기\n",
    "import pickle \n",
    "\n",
    "with open('./res/rag_data.pkl', 'rb') as f:\n",
    "    rag_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 10개 추출\n",
    "questions = rag_data['questions'][:10]\n",
    "contexts = rag_data['contexts'][:10]\n",
    "answers = rag_data['answers'][:10]\n",
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HyeonSeong\\Hateslop\\RAG-1stWeek\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline (w/o RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:48<00:00,  4.84s/it]\n"
     ]
    }
   ],
   "source": [
    "#GPT 답변 추출\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import call_openai, get_embeddings, cosine_similarity\n",
    "\n",
    "predictions = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    prompt = f\"\"\"Please answer to the question given below\n",
    "\n",
    "Question:\n",
    "{questions[i]}\n",
    "\"\"\"\n",
    "\n",
    "    prediction = call_openai(prompt, model='gpt-4o-2024-05-13')\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"연구자들은 AI가 저작권이 있는 자료를 잊어버리도록 돕기 위해 여러 가지 접근 방식을 사용하고 있습니다. 그 중 몇 가지 주요 접근 방식은 다음과 같습니다:\\n\\n1. **데이터 필터링 및 정제**: AI 모델을 훈련시키기 전에 저작권이 있는 자료를 필터링하고 제거하는 방법입니다. 이를 통해 AI가 저작권이 있는 자료를 학습하지 않도록 합니다.\\n\\n2. **모델 수정 및 업데이트**: 이미 훈련된 AI 모델에서 저작권이 있는 자료를 제거하기 위해 모델을 수정하거나 업데이트하는 방법입니다. 이를 위해 특정 데이터를 모델에서 '잊어버리게' 하는 기술이 연구되고 있습니다.\\n\\n3. **데이터 마스킹**: 저작권이 있는 자료를 마스킹하거나 변형하여 AI가 원본 자료를 인식하지 못하게 하는 방법입니다. 이를 통해 AI가 저작권 침해 없이 학습할 수 있도록 합니다.\\n\\n4. **법적 및 윤리적 가이드라인 준수**: AI 연구자들은 저작권법과 윤리적 가이드라인을 준수하여 AI 모델을 개발하고 있습니다. 이를 통해 저작권 침해를 방지하고, AI가 합법적으로 자료를 사용할 수 있도록 합니다.\\n\\n5. **기술적 솔루션 개발**: AI가 특정 데이터를 잊어버리도록 하는 기술적 솔루션을 개발하는 연구도 진행 중입니다. 예를 들어, '모델 잊기(forgetting)' 기술을 통해 AI가 특정 데이터를 기억하지 않도록 하는 방법이 있습니다.\\n\\n이러한 접근 방식을 통해 연구자들은 AI가 저작권이 있는 자료를 잊어버리고, 저작권 침해 없이 학습할 수 있도록 노력하고 있습니다.\",\n",
       " '2023년에 설립된 G7 AI 프레임워크의 목적은 인공지능(AI) 기술의 개발과 사용에 있어서 윤리적이고 책임 있는 접근을 촉진하는 것입니다. 이 프레임워크는 G7 국가들이 AI 기술의 잠재력을 최대한 활용하면서도, 개인의 프라이버시 보호, 데이터 보안, 공정성, 투명성 등의 중요한 윤리적 문제를 해결하기 위해 협력하는 것을 목표로 합니다. 이를 통해 AI 기술이 사회에 긍정적인 영향을 미치고, 신뢰할 수 있는 방식으로 발전할 수 있도록 지원합니다.',\n",
       " '현재 재단 모델과 관련하여 EU AI법 협상에 영향을 미치는 주요 과제는 다음과 같습니다:\\n\\n1. **책임성 및 투명성**: 재단 모델은 복잡하고 대규모 데이터셋을 사용하여 학습되기 때문에, 모델의 결정 과정이 불투명할 수 있습니다. 이는 AI 시스템의 결과에 대한 책임을 명확히 하는 데 어려움을 초래할 수 있습니다.\\n\\n2. **데이터 프라이버시 및 보안**: 재단 모델은 대량의 데이터를 필요로 하며, 이 데이터가 개인 정보일 경우 프라이버시 문제를 야기할 수 있습니다. EU의 GDPR과 같은 엄격한 데이터 보호 규정을 준수해야 하는 과제가 있습니다.\\n\\n3. **편향 및 공정성**: 재단 모델이 학습하는 데이터셋이 편향되어 있을 경우, 모델의 결과도 편향될 수 있습니다. 이는 공정성과 관련된 문제를 일으킬 수 있으며, 이를 해결하기 위한 규제 방안이 필요합니다.\\n\\n4. **표준화 및 규제 준수**: 재단 모델의 개발 및 사용에 대한 표준화된 규제 프레임워크가 부족합니다. 이는 다양한 이해관계자들이 일관된 방식으로 AI를 개발하고 사용할 수 있도록 하는 데 어려움을 초래합니다.\\n\\n5. **기술적 복잡성**: 재단 모델의 기술적 복잡성으로 인해 규제 당국이 이를 이해하고 적절히 규제하는 데 어려움이 있을 수 있습니다. 이는 규제의 효과성을 저해할 수 있습니다.\\n\\n6. **국제 협력**: AI 기술은 국경을 초월하여 사용되기 때문에, EU 내에서만 규제를 마련하는 것으로는 충분하지 않을 수 있습니다. 국제적인 협력과 조율이 필요합니다.\\n\\n이러한 과제들은 EU AI법 협상 과정에서 중요한 논의 주제가 되며, 이를 해결하기 위한 다양한 접근법과 전략이 필요합니다.',\n",
       " 'EU AI 법, 공식적으로 \"인공지능 법안\" (Artificial Intelligence Act, AIA)은 유럽 연합이 인공지능 기술의 개발과 사용을 규제하기 위해 제안한 법안입니다. 이 법안의 주요 목적은 인공지능 시스템의 안전성과 신뢰성을 보장하고, 인공지능 기술이 유럽 시민의 기본 권리와 자유를 침해하지 않도록 하는 것입니다.\\n\\nEU AI 법의 주요 의미는 다음과 같습니다:\\n\\n1. **위험 기반 접근**: 이 법안은 인공지능 시스템을 위험 수준에 따라 분류합니다. 예를 들어, 고위험 AI 시스템은 더 엄격한 규제를 받게 되며, 저위험 AI 시스템은 비교적 덜 엄격한 규제를 받습니다. 이는 인공지능 기술의 잠재적 위험을 최소화하고, 안전한 사용을 촉진하기 위한 것입니다.\\n\\n2. **투명성과 설명 가능성**: 인공지능 시스템의 투명성을 높이기 위해, 개발자와 사용자에게 시스템의 작동 방식과 의사 결정 과정을 설명할 수 있는 의무를 부과합니다. 이는 사용자가 AI 시스템의 결정을 이해하고 신뢰할 수 있도록 돕기 위한 것입니다.\\n\\n3. **데이터 관리**: AI 시스템의 학습에 사용되는 데이터의 품질과 공정성을 보장하기 위한 규정을 포함합니다. 이는 데이터 편향을 줄이고, AI 시스템이 공정하고 정확한 결정을 내릴 수 있도록 하기 위한 것입니다.\\n\\n4. **감독 및 집행**: 각 회원국은 AI 법의 준수를 감독하고 집행할 책임이 있는 기관을 지정해야 합니다. 이는 법안의 효과적인 시행을 보장하기 위한 것입니다.\\n\\n5. **윤리적 기준**: 인공지능 기술이 윤리적 기준을 준수하도록 하여, 인간의 존엄성과 기본 권리를 보호합니다. 이는 AI 기술이 사회에 긍정적인 영향을 미치도록 하기 위한 것입니다.\\n\\nEU AI 법은 인공지능 기술의 책임 있는 개발과 사용을 촉진하고, 유럽 연합 내에서 AI 기술의 혁신을 지원하면서도, 시민의 권리와 안전을 보호하는 것을 목표로 하고 있습니다.',\n",
       " 'AI 애플리케이션의 맥락에서 성능 평가의 중요성은 매우 큽니다. 다음은 그 이유를 설명하는 몇 가지 주요 포인트입니다:\\n\\n1. **정확성 및 신뢰성 보장**: AI 모델이 정확하게 작동하는지 확인하는 것은 매우 중요합니다. 성능 평가를 통해 모델의 예측이 얼마나 정확한지, 오류율이 얼마나 낮은지를 파악할 수 있습니다.\\n\\n2. **모델 개선**: 성능 평가 결과를 바탕으로 모델의 약점을 파악하고, 이를 개선하기 위한 피드백을 얻을 수 있습니다. 이를 통해 지속적으로 모델의 성능을 향상시킬 수 있습니다.\\n\\n3. **비교 및 선택**: 여러 모델이나 알고리즘을 비교할 때 성능 평가가 필수적입니다. 이를 통해 가장 적합한 모델을 선택할 수 있습니다.\\n\\n4. **실제 적용 가능성 판단**: 모델이 실제 환경에서 얼마나 잘 작동할지를 예측할 수 있습니다. 이는 모델이 실질적인 비즈니스 문제를 해결하는 데 얼마나 유용한지를 판단하는 데 도움이 됩니다.\\n\\n5. **신뢰성 확보**: 사용자나 고객에게 AI 시스템의 신뢰성을 보장하기 위해 성능 평가가 필요합니다. 이는 AI 시스템의 채택과 사용을 촉진하는 데 중요한 역할을 합니다.\\n\\n6. **윤리적 고려**: AI 모델이 공정하고 편향되지 않게 작동하는지 확인하는 것도 성능 평가의 중요한 부분입니다. 이를 통해 사회적 책임을 다할 수 있습니다.\\n\\n7. **법적 및 규제 준수**: 많은 산업에서 AI 시스템의 성능을 평가하고 검증하는 것이 법적 요구사항이 될 수 있습니다. 이를 통해 규제 준수를 보장할 수 있습니다.\\n\\n따라서, AI 애플리케이션의 성능 평가는 모델의 성공적인 개발, 배포 및 운영에 필수적인 요소입니다.',\n",
       " 'G7 회의에서 논의된 첨단 AI 시스템을 위한 국제 행동 강령의 목적은 인공지능 기술의 개발과 사용에 있어 안전성, 윤리성, 투명성을 보장하는 것입니다. 이를 통해 AI 기술이 사회에 긍정적인 영향을 미치고, 잠재적인 위험을 최소화하며, 국제적인 협력을 통해 일관된 규제와 표준을 마련하는 것을 목표로 합니다. 이러한 행동 강령은 AI 기술이 인류의 복지와 공공의 이익을 증진시키는 방향으로 발전하도록 유도하는 데 중점을 둡니다.',\n",
       " '미국 연방거래위원회(FTC)가 미국 저작권청에 제출한 의견서에서 제기한 문제는 주로 인공지능(AI)과 관련된 저작권 문제입니다. FTC는 AI가 생성한 콘텐츠의 저작권 보호 여부, AI 기술이 저작권을 침해할 가능성, 그리고 AI 시스템이 학습하는 과정에서 저작권이 있는 자료를 사용하는 문제 등을 다루었습니다. 이러한 문제들은 AI 기술의 발전과 함께 저작권법의 적용 범위와 해석에 대한 새로운 도전 과제를 제기하고 있습니다. FTC는 이러한 문제들을 해결하기 위해 명확한 가이드라인과 규제의 필요성을 강조했습니다.',\n",
       " 'EU AI 법에 명시된 AI 거버넌스의 주요 측면은 다음과 같습니다:\\n\\n1. **위험 기반 접근법**: AI 시스템을 위험 수준에 따라 분류하고, 이에 따라 규제 요구사항을 다르게 적용합니다. 예를 들어, 고위험 AI 시스템은 더 엄격한 규제를 받습니다.\\n\\n2. **투명성 및 설명 가능성**: AI 시스템의 작동 방식에 대한 투명성을 보장하고, 사용자가 AI의 결정을 이해할 수 있도록 설명 가능성을 요구합니다.\\n\\n3. **데이터 관리 및 품질**: AI 시스템의 학습에 사용되는 데이터의 품질과 관리에 대한 엄격한 기준을 설정하여, 데이터 편향을 최소화하고 신뢰성을 높입니다.\\n\\n4. **인간 감독**: AI 시스템의 사용 과정에서 인간의 감독을 보장하여, AI가 자율적으로 중요한 결정을 내리지 않도록 합니다.\\n\\n5. **안전 및 보안**: AI 시스템이 안전하게 작동하고, 보안 위협에 대응할 수 있도록 보장합니다.\\n\\n6. **책임 및 책임성**: AI 시스템의 개발자와 운영자가 그들의 시스템에 대해 책임을 지도록 하고, 문제가 발생했을 때 책임을 명확히 합니다.\\n\\n7. **윤리적 원칙 준수**: AI 시스템이 윤리적 원칙을 준수하도록 하여, 인간의 존엄성과 기본 권리를 침해하지 않도록 합니다.\\n\\n8. **규제 기관 및 감독**: 각국의 규제 기관이 AI 시스템의 준수 여부를 감독하고, 필요한 경우 제재를 가할 수 있는 권한을 부여합니다.\\n\\n이러한 측면들은 AI 기술의 안전하고 윤리적인 사용을 보장하기 위해 마련된 것입니다.',\n",
       " 'G7 히로시마 프로세스 첨단 AI 시스템을 위한 국제 행동 강령에서 논의되는 AI 안전 조치의 주요 구성 요소는 다음과 같습니다:\\n\\n1. **투명성**: AI 시스템의 작동 원리와 의사 결정 과정을 명확히 설명하고, 이해 관계자들이 이를 이해할 수 있도록 하는 것.\\n\\n2. **책임성**: AI 시스템의 개발, 배포 및 사용에 대한 책임을 명확히 하고, 문제가 발생했을 때 이를 해결할 수 있는 메커니즘을 마련하는 것.\\n\\n3. **공정성**: AI 시스템이 편향되지 않고 공정하게 작동하도록 보장하며, 다양한 사회적, 문화적 배경을 고려하는 것.\\n\\n4. **안전성**: AI 시스템이 예측 가능한 방식으로 작동하고, 잠재적인 위험을 최소화하며, 악의적인 사용을 방지하는 것.\\n\\n5. **프라이버시 보호**: AI 시스템이 개인의 프라이버시를 침해하지 않도록 하고, 데이터 보호 규정을 준수하는 것.\\n\\n6. **윤리적 고려**: AI 시스템이 윤리적 기준을 준수하며, 인간의 존엄성과 권리를 존중하는 것.\\n\\n7. **협력과 조정**: 국제 사회가 협력하여 AI 안전 조치를 마련하고, 표준과 규범을 조정하는 것.\\n\\n이러한 구성 요소들은 AI 기술이 안전하고 책임감 있게 사용될 수 있도록 보장하며, 사회적 신뢰를 구축하는 데 중요한 역할을 합니다.',\n",
       " '2027년까지 AI 시장의 예상 성장률은 다양한 연구 기관과 시장 조사 보고서에 따라 다를 수 있습니다. 예를 들어, MarketsandMarkets의 보고서에 따르면, 글로벌 AI 시장은 2022년부터 2027년까지 연평균 성장률(CAGR) 39.7%로 성장할 것으로 예상됩니다. 다른 보고서들도 비슷한 성장률을 제시하고 있습니다.\\n\\n정확한 수치는 출처에 따라 다를 수 있으므로, 최신 보고서를 참조하는 것이 좋습니다.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:41<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          user_input  \\\n",
      "0  연구자들은 AI가 저작권이 있는 자료를 잊어버리도록 돕기 위해 어떤 접근 방식을 사...   \n",
      "1                 2023년에 설립된 G7 AI 프레임워크의 목적은 무엇인가요?   \n",
      "2       현재 재단 모델과 관련하여 EU AI법 협상에 영향을 미치는 과제는 무엇인가요?   \n",
      "3                  인공지능 규제와 관련하여 EU AI 법의 의미는 무엇인가요?   \n",
      "4                 AI 애플리케이션의 맥락에서 성능 평가의 중요성은 무엇인가요?   \n",
      "\n",
      "                                            response  \\\n",
      "0  연구자들은 AI가 저작권이 있는 자료를 잊어버리도록 돕기 위해 여러 가지 접근 방식...   \n",
      "1  2023년에 설립된 G7 AI 프레임워크의 목적은 인공지능(AI) 기술의 개발과 사...   \n",
      "2  현재 재단 모델과 관련하여 EU AI법 협상에 영향을 미치는 주요 과제는 다음과 같...   \n",
      "3  EU AI 법, 공식적으로 \"인공지능 법안\" (Artificial Intellige...   \n",
      "4  AI 애플리케이션의 맥락에서 성능 평가의 중요성은 매우 큽니다. 다음은 그 이유를 ...   \n",
      "\n",
      "                                           reference  factual_correctness  \n",
      "0  연구자들은 해리 포터를 통해 인공지능이 저작권이 있는 자료를 잊어버릴 수 있도록 돕...                 0.38  \n",
      "1  2023년에 설립된 G7 AI 프레임워크의 목적은 AI 기술의 책임 있는 개발과 사...                 0.57  \n",
      "2  프랑스, 독일, 이탈리아가 추진하고 있는 재단 모델에 대한 의무적 자율 규제의 필요...                 0.09  \n",
      "3  EU 인공지능법은 인공지능 기술과 관련된 위험을 다루는 프레임워크를 구축하여 인공지...                 0.52  \n",
      "4  AI 애플리케이션의 맥락에서 성능 평가의 중요성은 AI 시스템의 효과와 효율성을 평...                 0.42  \n"
     ]
    }
   ],
   "source": [
    "#FactualCorrectness: 생성된 답변이 주어진 문맥(또는 참조 데이터)과 비교했을 때 사실적으로 정확한지 평가\n",
    "from ragas.metrics import FactualCorrectness\n",
    "from ragas.dataset_schema import SingleTurnSample, EvaluationDataset\n",
    "from ragas import evaluate\n",
    "\n",
    "samples = []\n",
    "for context, question, ai_response, ground_truth in zip(contexts, questions, predictions, answers):\n",
    "    sample = SingleTurnSample(\n",
    "        retrieve_contexts=[context],\n",
    "        user_input=question,\n",
    "        response=ai_response,\n",
    "        reference=ground_truth\n",
    "    )\n",
    "    samples.append(sample)\n",
    "\n",
    "\n",
    "dataset = EvaluationDataset(samples)\n",
    "\n",
    "factual_correctness_metric = FactualCorrectness(llm=evaluator_llm)\n",
    "\n",
    "#준비된 데이터셋(dataset)과 메트릭(metrics)을 입력으로 받아, 평가 점수를 계산\n",
    "results = evaluate(dataset, metrics=[factual_correctness_metric])\n",
    "\n",
    "#평가 결과(results)를 Pandas 데이터프레임으로 변환 후 상위 5개 행 확인\n",
    "results_df = results.to_pandas()\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'factual_correctness': 0.2830}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연구자들은 AI가 저작권이 있는 자료를 잊어버리도록 돕기 위해 어떤 접근 방식을 사용하고 있나요?\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연구자들은 AI가 저작권이 있는 자료를 잊어버리도록 돕기 위해 여러 가지 접근 방식을 사용하고 있습니다. 그 중 몇 가지 주요 접근 방식은 다음과 같습니다:\n",
      "\n",
      "1. **데이터 필터링 및 정제**: AI 모델을 훈련시키기 전에 저작권이 있는 자료를 필터링하고 제거하는 방법입니다. 이를 통해 AI가 저작권이 있는 자료를 학습하지 않도록 합니다.\n",
      "\n",
      "2. **모델 수정 및 업데이트**: 이미 훈련된 AI 모델에서 저작권이 있는 자료를 제거하기 위해 모델을 수정하거나 업데이트하는 방법입니다. 이를 위해 특정 데이터를 모델에서 '잊어버리게' 하는 기술이 연구되고 있습니다.\n",
      "\n",
      "3. **데이터 마스킹**: 저작권이 있는 자료를 마스킹하거나 변형하여 AI가 원본 자료를 인식하지 못하게 하는 방법입니다. 이를 통해 AI가 저작권 침해 없이 학습할 수 있도록 합니다.\n",
      "\n",
      "4. **법적 및 윤리적 가이드라인 준수**: AI 연구자들은 저작권법과 윤리적 가이드라인을 준수하여 AI 모델을 개발하고 있습니다. 이를 통해 저작권 침해를 방지하고, AI가 합법적으로 자료를 사용할 수 있도록 합니다.\n",
      "\n",
      "5. **기술적 솔루션 개발**: AI가 특정 데이터를 잊어버리도록 하는 기술적 솔루션을 개발하는 연구도 진행 중입니다. 예를 들어, '모델 잊기(forgetting)' 기술을 통해 AI가 특정 데이터를 기억하지 않도록 하는 방법이 있습니다.\n",
      "\n",
      "이러한 접근 방식을 통해 연구자들은 AI가 저작권이 있는 자료를 잊어버리고, 저작권 침해 없이 학습할 수 있도록 노력하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:35<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "#context가 주어진 GPT 답변 추출\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import call_openai, get_embeddings, cosine_similarity\n",
    "\n",
    "predictions = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    prompt = f\"\"\"Please answer to the question given below from the context\n",
    "\n",
    "Context:\n",
    "{contexts[i]}\n",
    "\n",
    "Question:\n",
    "{questions[i]}\n",
    "\"\"\"\n",
    "\n",
    "    prediction = call_openai(prompt, model='gpt-4o-2024-05-13')\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:20<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          user_input  \\\n",
      "0  연구자들은 AI가 저작권이 있는 자료를 잊어버리도록 돕기 위해 어떤 접근 방식을 사...   \n",
      "1                 2023년에 설립된 G7 AI 프레임워크의 목적은 무엇인가요?   \n",
      "2       현재 재단 모델과 관련하여 EU AI법 협상에 영향을 미치는 과제는 무엇인가요?   \n",
      "3                  인공지능 규제와 관련하여 EU AI 법의 의미는 무엇인가요?   \n",
      "4                 AI 애플리케이션의 맥락에서 성능 평가의 중요성은 무엇인가요?   \n",
      "\n",
      "                                            response  \\\n",
      "0  주어진 문맥에서는 연구자들이 AI가 저작권이 있는 자료를 잊어버리도록 돕기 위한 특...   \n",
      "1  2023년에 설립된 G7 AI 프레임워크의 목적은 첨단 AI 시스템을 개발하는 기업...   \n",
      "2  현재 재단 모델과 관련하여 EU AI법 협상에 영향을 미치는 과제는 다음과 같습니다...   \n",
      "3  EU AI 법(AI Act)은 유럽연합(EU) 내에서 인공지능(AI) 기술의 개발과...   \n",
      "4  AI 애플리케이션의 맥락에서 성능 평가의 중요성은 다음과 같은 이유들로 설명될 수 ...   \n",
      "\n",
      "                                           reference  factual_correctness  \n",
      "0  연구자들은 해리 포터를 통해 인공지능이 저작권이 있는 자료를 잊어버릴 수 있도록 돕...                 0.33  \n",
      "1  2023년에 설립된 G7 AI 프레임워크의 목적은 AI 기술의 책임 있는 개발과 사...                 0.29  \n",
      "2  프랑스, 독일, 이탈리아가 추진하고 있는 재단 모델에 대한 의무적 자율 규제의 필요...                 0.29  \n",
      "3  EU 인공지능법은 인공지능 기술과 관련된 위험을 다루는 프레임워크를 구축하여 인공지...                 0.44  \n",
      "4  AI 애플리케이션의 맥락에서 성능 평가의 중요성은 AI 시스템의 효과와 효율성을 평...                 0.27  \n"
     ]
    }
   ],
   "source": [
    "#context가 주어진 상태의 답변 평가\n",
    "from ragas.metrics import FactualCorrectness\n",
    "from ragas.dataset_schema import SingleTurnSample, EvaluationDataset\n",
    "from ragas import evaluate\n",
    "\n",
    "samples = []\n",
    "for context, question, ai_response, ground_truth in zip(contexts, questions, predictions, answers):\n",
    "    sample = SingleTurnSample(\n",
    "        retrieve_contexts=[context],\n",
    "        user_input=question,\n",
    "        response=ai_response,\n",
    "        reference=ground_truth\n",
    "    )\n",
    "    samples.append(sample)\n",
    "\n",
    "\n",
    "dataset = EvaluationDataset(samples)\n",
    "\n",
    "factual_correctness_metric = FactualCorrectness(llm=evaluator_llm)\n",
    "\n",
    "#준비된 데이터셋(dataset)과 메트릭(metrics)을 입력으로 받아, 평가 점수를 계산\n",
    "results = evaluate(dataset, metrics=[factual_correctness_metric])\n",
    "\n",
    "#평가 결과(results)를 Pandas 데이터프레임으로 변환 후 상위 5개 행 확인\n",
    "results_df = results.to_pandas()\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'factual_correctness': 0.2160}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 문맥에서는 연구자들이 AI가 저작권이 있는 자료를 잊어버리도록 돕기 위한 특정 접근 방식에 대해 언급하고 있지 않습니다. 문맥은 주로 편향된 훈련 데이터에 대한 분석 기술, 민감한 정보를 포함하는 AI 시스템에 대한 미세 조정 방법, 그리고 정보 공유 채널 구축에 관한 내용을 다루고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연구자들은 해리 포터를 통해 인공지능이 저작권이 있는 자료를 잊어버릴 수 있도록 돕고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(answers[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
